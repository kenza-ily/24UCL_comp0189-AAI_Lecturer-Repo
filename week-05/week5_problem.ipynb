{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimdanny/COMP0189-practical/blob/main/Week-06/deepglobe_land_cover_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_IlD1eeQItn",
        "papermill": {
          "duration": 0.024489,
          "end_time": "2020-11-11T04:19:40.496749",
          "exception": false,
          "start_time": "2020-11-11T04:19:40.472260",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# COMP0189: Applied Artificial Intelligence\n",
        "## Week 6 (Deep Learning - image segmentation)\n",
        "\n",
        "In this notebook we use [Unet](https://arxiv.org/abs/1505.04597) for Land Cover Classfication from Satellite Imagery using DeepGlobe Land Cover Classification Dataset. After this week you will be able to ...\n",
        "\n",
        "- Train U-Net models in PyTorch.\n",
        "- How to implement Dice loss and BCE-Dice loss.\n",
        "- Visualize the prediction output on some of the test images using the trained U-Net.\n",
        "- Learn how data augmentation affects the training model.\n",
        "- Compute the area of one class on the test set ground truth, the same class on the predicted masks on the same test set, and compute the difference between the two to see the error of your predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfbTqV1tQIto",
        "papermill": {
          "duration": 0.022878,
          "end_time": "2020-11-11T04:19:40.542961",
          "exception": false,
          "start_time": "2020-11-11T04:19:40.520083",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Libraries üìö‚¨á"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZZjQKj93uQA"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation-models-pytorch==0.2.0\n",
        "!pip install opencv-python\n",
        "!pip install albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2020-11-11T04:19:40.598993Z",
          "iopub.status.busy": "2020-11-11T04:19:40.598327Z",
          "iopub.status.idle": "2020-11-11T04:19:43.727682Z",
          "shell.execute_reply": "2020-11-11T04:19:43.726567Z"
        },
        "id": "Cd_Q_EbIQItp",
        "papermill": {
          "duration": 3.161749,
          "end_time": "2020-11-11T04:19:43.727814",
          "exception": false,
          "start_time": "2020-11-11T04:19:40.566065",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os, cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random, tqdm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import albumentations as album"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:19:43.781230Z",
          "iopub.status.busy": "2020-11-11T04:19:43.780452Z",
          "iopub.status.idle": "2020-11-11T04:20:00.661333Z",
          "shell.execute_reply": "2020-11-11T04:20:00.660741Z"
        },
        "id": "pB2TsGb-QItq",
        "papermill": {
          "duration": 16.909556,
          "end_time": "2020-11-11T04:20:00.661450",
          "exception": false,
          "start_time": "2020-11-11T04:19:43.751894",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqGHSsB4om4b"
      },
      "outputs": [],
      "source": [
        "# Getting dataset's metadata\n",
        "! wget https://raw.githubusercontent.com/kimdanny/COMP0189-practical/main/data/class_dict.csv\n",
        "! wget https://raw.githubusercontent.com/kimdanny/COMP0189-practical/main/data/metadata.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeRyCVvTm6ZM"
      },
      "outputs": [],
      "source": [
        "# Downloading dataset\n",
        "! wget https://competitions.codalab.org/my/datasets/download/b6def20d-34c5-4871-8d9d-d97075179ea0 -O land-train.zip\n",
        "! wget https://competitions.codalab.org/my/datasets/download/dfb325b3-4e9c-43c0-93b3-036eec5fa773 -O land_valid_sat.zip\n",
        "! wget https://competitions.codalab.org/my/datasets/download/61ac1b46-9bd3-4694-810f-ffd08a7f832a -O land_test_sat.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cFThp64obH4"
      },
      "outputs": [],
      "source": [
        "! unzip -qq land-train.zip\n",
        "! mv land-train train\n",
        "! unzip -qq land_valid_sat.zip -d valid\n",
        "! unzip -qq land_test_sat.zip -d test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JuDPChTQItq",
        "papermill": {
          "duration": 0.023301,
          "end_time": "2020-11-11T04:20:00.708750",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.685449",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Read Data & Create train / valid splits üìÅ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:00.768015Z",
          "iopub.status.busy": "2020-11-11T04:20:00.767115Z",
          "iopub.status.idle": "2020-11-11T04:20:00.796084Z",
          "shell.execute_reply": "2020-11-11T04:20:00.796568Z"
        },
        "id": "ogMMvJUBQItr",
        "papermill": {
          "duration": 0.064492,
          "end_time": "2020-11-11T04:20:00.796691",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.732199",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "DATA_DIR = ''\n",
        "\n",
        "metadata_df = pd.read_csv(os.path.join(DATA_DIR, 'metadata.csv'))\n",
        "metadata_df = metadata_df[metadata_df['split']=='train']\n",
        "metadata_df = metadata_df[['image_id', 'sat_image_path', 'mask_path']]\n",
        "metadata_df['sat_image_path'] = metadata_df['sat_image_path'].apply(lambda img_pth: os.path.join(DATA_DIR, img_pth))\n",
        "metadata_df['mask_path'] = metadata_df['mask_path'].apply(lambda img_pth: os.path.join(DATA_DIR, img_pth))\n",
        "# Shuffle DataFrame\n",
        "metadata_df = metadata_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Perform 90/10 split for train / val\n",
        "valid_df = metadata_df.sample(frac=0.1, random_state=42)\n",
        "train_df = metadata_df.drop(valid_df.index)\n",
        "len(train_df), len(valid_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:00.852070Z",
          "iopub.status.busy": "2020-11-11T04:20:00.851216Z",
          "iopub.status.idle": "2020-11-11T04:20:00.860652Z",
          "shell.execute_reply": "2020-11-11T04:20:00.859981Z"
        },
        "id": "PrS7OOwqQIts",
        "papermill": {
          "duration": 0.03956,
          "end_time": "2020-11-11T04:20:00.860779",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.821219",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class_dict = pd.read_csv(os.path.join(DATA_DIR, 'class_dict.csv'))\n",
        "# Get class names\n",
        "class_names = class_dict['name'].tolist()\n",
        "# Get class RGB values\n",
        "class_rgb_values = class_dict[['r','g','b']].values.tolist()\n",
        "\n",
        "print('All dataset classes and their corresponding RGB values in labels:')\n",
        "print('Class Names: ', class_names)\n",
        "print('Class RGB values: ', class_rgb_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_eVnHo2QIts",
        "papermill": {
          "duration": 0.024557,
          "end_time": "2020-11-11T04:20:00.910401",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.885844",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "#### Shortlist specific classes to segment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:00.966519Z",
          "iopub.status.busy": "2020-11-11T04:20:00.965617Z",
          "iopub.status.idle": "2020-11-11T04:20:00.970796Z",
          "shell.execute_reply": "2020-11-11T04:20:00.970160Z"
        },
        "id": "K55PxIauQItt",
        "papermill": {
          "duration": 0.036145,
          "end_time": "2020-11-11T04:20:00.970921",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.934776",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Useful to shortlist specific classes in datasets with large number of classes\n",
        "select_classes = ['urban_land', 'agriculture_land', 'rangeland', 'forest_land', 'water', 'barren_land', 'unknown']\n",
        "\n",
        "# Get RGB values of required classes\n",
        "select_class_indices = [class_names.index(cls.lower()) for cls in select_classes]\n",
        "select_class_rgb_values =  np.array(class_rgb_values)[select_class_indices]\n",
        "\n",
        "print('Selected classes and their corresponding RGB values in labels:')\n",
        "print('Class Names: ', class_names)\n",
        "print('Class RGB values: ', class_rgb_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdGCpfjsQItt",
        "papermill": {
          "duration": 0.024734,
          "end_time": "2020-11-11T04:20:01.021071",
          "exception": false,
          "start_time": "2020-11-11T04:20:00.996337",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Helper functions for viz. & one-hot encoding/decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:01.080389Z",
          "iopub.status.busy": "2020-11-11T04:20:01.079533Z",
          "iopub.status.idle": "2020-11-11T04:20:01.088228Z",
          "shell.execute_reply": "2020-11-11T04:20:01.087750Z"
        },
        "id": "59bU68D0QItt",
        "papermill": {
          "duration": 0.042035,
          "end_time": "2020-11-11T04:20:01.088327",
          "exception": false,
          "start_time": "2020-11-11T04:20:01.046292",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# helper function for data visualization\n",
        "def visualize(**images):\n",
        "    \"\"\"\n",
        "    Plot images in one row\n",
        "    \"\"\"\n",
        "    n_images = len(images)\n",
        "    plt.figure(figsize=(20,8))\n",
        "    for idx, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n_images, idx + 1)\n",
        "        plt.xticks([]);\n",
        "        plt.yticks([])\n",
        "        # get title from the parameter names\n",
        "        plt.title(name.replace('_',' ').title(), fontsize=20)\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "# Perform one hot encoding on label\n",
        "def one_hot_encode(label, label_values):\n",
        "    \"\"\"\n",
        "    Convert a segmentation image label array to one-hot format\n",
        "    by replacing each pixel value with a vector of length num_classes\n",
        "    # Arguments\n",
        "        label: The 2D array segmentation image label\n",
        "        label_values\n",
        "\n",
        "    # Returns\n",
        "        A 2D array with the same width and hieght as the input, but\n",
        "        with a depth size of num_classes\n",
        "    \"\"\"\n",
        "    semantic_map = []\n",
        "    for colour in label_values:\n",
        "        equality = np.equal(label, colour)\n",
        "        class_map = np.all(equality, axis = -1)\n",
        "        semantic_map.append(class_map)\n",
        "    semantic_map = np.stack(semantic_map, axis=-1)\n",
        "\n",
        "    return semantic_map\n",
        "\n",
        "# Perform reverse one-hot-encoding on labels / preds\n",
        "def reverse_one_hot(image):\n",
        "    \"\"\"\n",
        "    Transform a 2D array in one-hot format (depth is num_classes),\n",
        "    to a 2D array with only 1 channel, where each pixel value is\n",
        "    the classified class key.\n",
        "    # Arguments\n",
        "        image: The one-hot format image\n",
        "\n",
        "    # Returns\n",
        "        A 2D array with the same width and hieght as the input, but\n",
        "        with a depth size of 1, where each pixel value is the classified\n",
        "        class key.\n",
        "    \"\"\"\n",
        "    x = np.argmax(image, axis = -1)\n",
        "    return x\n",
        "\n",
        "# Perform colour coding on the reverse-one-hot outputs\n",
        "def colour_code_segmentation(image, label_values):\n",
        "    \"\"\"\n",
        "    Given a 1-channel array of class keys, colour code the segmentation results.\n",
        "    # Arguments\n",
        "        image: single channel array where each value represents the class key.\n",
        "        label_values\n",
        "\n",
        "    # Returns\n",
        "        Colour coded image for segmentation visualization\n",
        "    \"\"\"\n",
        "    colour_codes = np.array(label_values)\n",
        "    x = colour_codes[image.astype(int)]\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "714IWFiotSka"
      },
      "source": [
        "## Custom Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:01.142187Z",
          "iopub.status.busy": "2020-11-11T04:20:01.141334Z",
          "iopub.status.idle": "2020-11-11T04:20:01.153771Z",
          "shell.execute_reply": "2020-11-11T04:20:01.154347Z"
        },
        "id": "N2Zf_hGOQItu",
        "papermill": {
          "duration": 0.041149,
          "end_time": "2020-11-11T04:20:01.154457",
          "exception": false,
          "start_time": "2020-11-11T04:20:01.113308",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class LandCoverDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    \"\"\"DeepGlobe Land Cover Classification Challenge Dataset. Read images, apply augmentation and preprocessing transformations.\n",
        "\n",
        "    Args:\n",
        "        df (str): DataFrame containing images / labels paths\n",
        "        class_rgb_values (list): RGB values of select classes to extract from segmentation mask\n",
        "        augmentation (albumentations.Compose): data transfromation pipeline\n",
        "            (e.g. flip, scale, etc.)\n",
        "        preprocessing (albumentations.Compose): data preprocessing\n",
        "            (e.g. noralization, shape manipulation, etc.)\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            df,\n",
        "            class_rgb_values=None,\n",
        "            augmentation=None,\n",
        "            preprocessing=None,\n",
        "    ):\n",
        "        self.image_paths = df['sat_image_path'].tolist()\n",
        "        self.mask_paths = df['mask_path'].tolist()\n",
        "\n",
        "        self.class_rgb_values = class_rgb_values\n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "\n",
        "        # read images and masks\n",
        "        image = cv2.cvtColor(cv2.imread(self.image_paths[i]), cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.cvtColor(cv2.imread(self.mask_paths[i]), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # one-hot-encode the mask\n",
        "        mask = one_hot_encode(mask, self.class_rgb_values).astype('float')\n",
        "\n",
        "        # apply augmentations\n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        # apply preprocessing\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        # return length of\n",
        "        return len(self.image_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2ld70i2QItv",
        "papermill": {
          "duration": 0.0248,
          "end_time": "2020-11-11T04:20:01.204614",
          "exception": false,
          "start_time": "2020-11-11T04:20:01.179814",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "#### Visualize Sample Image and Mask üìà"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:01.262566Z",
          "iopub.status.busy": "2020-11-11T04:20:01.261449Z",
          "iopub.status.idle": "2020-11-11T04:20:04.972786Z",
          "shell.execute_reply": "2020-11-11T04:20:04.972272Z"
        },
        "id": "EBC4RuDuQItv",
        "papermill": {
          "duration": 3.743046,
          "end_time": "2020-11-11T04:20:04.972888",
          "exception": false,
          "start_time": "2020-11-11T04:20:01.229842",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "dataset = LandCoverDataset(train_df, class_rgb_values=select_class_rgb_values)\n",
        "random_idx = random.randint(0, len(dataset)-1)\n",
        "image, mask = dataset[2]\n",
        "\n",
        "visualize(\n",
        "    original_image = image,\n",
        "    ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n",
        "    one_hot_encoded_mask = reverse_one_hot(mask)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13lJ1tyTQItw",
        "papermill": {
          "duration": 0.031599,
          "end_time": "2020-11-11T04:20:05.037746",
          "exception": false,
          "start_time": "2020-11-11T04:20:05.006147",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Defining Augmentation and preprocessing pipeline for data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:05.112791Z",
          "iopub.status.busy": "2020-11-11T04:20:05.111981Z",
          "iopub.status.idle": "2020-11-11T04:20:05.115075Z",
          "shell.execute_reply": "2020-11-11T04:20:05.114478Z"
        },
        "id": "VQQlWcOtQItw",
        "papermill": {
          "duration": 0.045522,
          "end_time": "2020-11-11T04:20:05.115181",
          "exception": false,
          "start_time": "2020-11-11T04:20:05.069659",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_training_augmentation():\n",
        "    train_transform = [\n",
        "        album.RandomCrop(height=1024, width=1024, always_apply=True),\n",
        "        album.HorizontalFlip(p=0.5),\n",
        "        album.VerticalFlip(p=0.5),\n",
        "    ]\n",
        "    return album.Compose(train_transform)\n",
        "\n",
        "\n",
        "def get_validation_augmentation():\n",
        "    train_transform = [\n",
        "        album.CenterCrop(height=1024, width=1024, always_apply=True),\n",
        "    ]\n",
        "    return album.Compose(train_transform)\n",
        "\n",
        "\n",
        "def get_training_no_augmentation():\n",
        "    train_transform = [\n",
        "        album.CenterCrop(height=1024, width=1024, always_apply=True),\n",
        "    ]\n",
        "    return album.Compose(train_transform)\n",
        "\n",
        "\n",
        "def to_tensor(x, **kwargs):\n",
        "    return x.transpose(2, 0, 1).astype('float32')\n",
        "\n",
        "\n",
        "def get_preprocessing(preprocessing_fn=None):\n",
        "    \"\"\"Construct preprocessing transform\n",
        "    Args:\n",
        "        preprocessing_fn (callable): data normalization function\n",
        "            (can be specific for each pretrained neural network)\n",
        "    Return:\n",
        "        transform: albumentations.Compose\n",
        "    \"\"\"\n",
        "    _transform = []\n",
        "    if preprocessing_fn:\n",
        "        _transform.append(album.Lambda(image=preprocessing_fn))\n",
        "    _transform.append(album.Lambda(image=to_tensor, mask=to_tensor))\n",
        "\n",
        "    return album.Compose(_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhkhbBjgQItx",
        "papermill": {
          "duration": 0.03172,
          "end_time": "2020-11-11T04:20:05.179602",
          "exception": false,
          "start_time": "2020-11-11T04:20:05.147882",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "#### Visualize Augmented Images & Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:05.250381Z",
          "iopub.status.busy": "2020-11-11T04:20:05.249704Z",
          "iopub.status.idle": "2020-11-11T04:20:11.456620Z",
          "shell.execute_reply": "2020-11-11T04:20:11.457108Z"
        },
        "id": "eiKMEI5DQIty",
        "papermill": {
          "duration": 6.245534,
          "end_time": "2020-11-11T04:20:11.457241",
          "exception": false,
          "start_time": "2020-11-11T04:20:05.211707",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "augmented_dataset = LandCoverDataset(\n",
        "    train_df,\n",
        "    augmentation=get_training_augmentation(),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "image, mask = augmented_dataset[2]\n",
        "visualize(\n",
        "        original_image = image,\n",
        "        ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n",
        "        one_hot_encoded_mask = reverse_one_hot(mask))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEU8DKdFQIty",
        "papermill": {
          "duration": 0.05496,
          "end_time": "2020-11-11T04:20:11.565134",
          "exception": false,
          "start_time": "2020-11-11T04:20:11.510174",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Training Unet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wWLNIJdQItz",
        "papermill": {
          "duration": 0.052843,
          "end_time": "2020-11-11T04:20:11.772393",
          "exception": false,
          "start_time": "2020-11-11T04:20:11.719550",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:11.881284Z",
          "iopub.status.busy": "2020-11-11T04:20:11.880373Z",
          "iopub.status.idle": "2020-11-11T04:20:17.009902Z",
          "shell.execute_reply": "2020-11-11T04:20:17.009318Z"
        },
        "id": "a3ZHSlQyQItz",
        "papermill": {
          "duration": 5.187035,
          "end_time": "2020-11-11T04:20:17.010064",
          "exception": false,
          "start_time": "2020-11-11T04:20:11.823029",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "ENCODER = 'resnet50'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "CLASSES = select_classes\n",
        "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
        "\n",
        "\n",
        "\n",
        "model = smp.Unet(\n",
        "    encoder_name=ENCODER,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
        "    encoder_weights=ENCODER_WEIGHTS,     # use `imagenet` pre-trained weights for encoder initialization\n",
        "   classes=len(CLASSES),\n",
        "    activation=ACTIVATION,# model output channels (number of classes in your dataset)\n",
        ")\n",
        "\n",
        "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NKfm2i9QIt0",
        "papermill": {
          "duration": 0.050739,
          "end_time": "2020-11-11T04:20:17.327158",
          "exception": false,
          "start_time": "2020-11-11T04:20:17.276419",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "#Task 1: Diceloss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndRpE6rV_Gy0"
      },
      "source": [
        "Implement the 1-dice loss\n",
        "(https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3W7EY0PNiwi"
      },
      "outputs": [],
      "source": [
        "def f_score(pr, gt, beta=1, eps=1e-7, threshold=None, activation='sigmoid'):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        pr (torch.Tensor): A list of predicted elements\n",
        "        gt (torch.Tensor):  A list of elements that are to be predicted\n",
        "        eps (float): epsilon to avoid zero division\n",
        "        threshold: threshold for outputs binarization\n",
        "    Returns:\n",
        "        float: IoU (Jaccard) score\n",
        "    \"\"\"\n",
        "\n",
        "    if activation is None or activation == \"none\":\n",
        "        activation_fn = lambda x: x\n",
        "    elif activation == \"sigmoid\":\n",
        "        activation_fn = torch.nn.Sigmoid()\n",
        "    elif activation == \"softmax2d\":\n",
        "        activation_fn = torch.nn.Softmax2d()\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            \"Activation implemented for sigmoid and softmax2d\"\n",
        "        )\n",
        "     #code\n",
        "    \n",
        "\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    __name__ = 'dice_loss'\n",
        "\n",
        "    def __init__(self, eps=1e-7, activation='sigmoid'):\n",
        "        super().__init__()\n",
        "        self.activation = activation\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, y_pr, y_gt):\n",
        "         #code\n",
        "        \n",
        "\n",
        "\n",
        "class BCEDiceLoss(DiceLoss):\n",
        "    __name__ = 'bce_dice_loss'\n",
        "\n",
        "    def __init__(self, eps=1e-7, activation='sigmoid', lambda_dice=1.0, lambda_bce=1.0):\n",
        "        super().__init__(eps, activation)\n",
        "        if activation == None:\n",
        "            self.bce = nn.BCELoss(reduction='mean')\n",
        "        else:\n",
        "            self.bce = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "        self.lambda_dice=lambda_dice\n",
        "        self.lambda_bce=lambda_bce\n",
        "\n",
        "    def forward(self, y_pr, y_gt):\n",
        "        #code\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrLRswvhTFNL"
      },
      "source": [
        "#Task 2: To see the effect of data augmentation, we will do ablation. Let's train the model without the data augmentation.\n",
        "\n",
        "By not passing the `augmentation` parameter when initializing the `LandCoverDataset`, you can create a data loader that does not contain the augmented image data. However, in this notebook (for educational purpose), just to resize the image, we created a separate function (`get_training_no_augmentation()`). Passing an image without resizing it will cause memory error as the image size is bigger than the Colab's GPU capacity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KArxixSgTI6i"
      },
      "outputs": [],
      "source": [
        "# Get train and val dataset instances\n",
        "train_dataset_without_aug = LandCoverDataset(train_df,\n",
        "\n",
        "                                             augmentation=get_training_no_augmentation(),\n",
        "                                                  preprocessing=get_preprocessing(preprocessing_fn),\n",
        "                                                   class_rgb_values=select_class_rgb_values)\n",
        "\n",
        "valid_dataset = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "# create test dataloader to be used with Unet model (with preprocessing operation: to_tensor(...))\n",
        "test_dataset = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Get train and val data loaders\n",
        "train_loader = DataLoader(train_dataset_without_aug, batch_size=4, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
        "test_dataloader = DataLoader(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFoC0N0dqUSr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# test dataset for visualization (without preprocessing augmentations & transformations)\n",
        "test_dataset_vis = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "# get a random test image/mask index\n",
        "random_idx = random.randint(0, len(test_dataset_vis)-1)\n",
        "image, mask = test_dataset_vis[random_idx]\n",
        "\n",
        "visualize(\n",
        "    original_image = image,\n",
        "    ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n",
        "    one_hot_encoded_mask = reverse_one_hot(mask)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXW6AI4zThcs"
      },
      "outputs": [],
      "source": [
        "# Set flag to train the model or not. If set to 'False', only prediction is performed (using an older model checkpoint)\n",
        "TRAINING = True\n",
        "\n",
        "# Set num of epochs\n",
        "EPOCHS = 2\n",
        "\n",
        "# Set device: `cuda` or `cpu`\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# define loss function\n",
        "# loss = DiceLoss()\n",
        "\n",
        "\n",
        "# define metrics\n",
        "metrics = [\n",
        "    smp.utils.metrics.IoU(threshold=0.5),\n",
        "]\n",
        "\n",
        "# define optimizer\n",
        "optimizer = torch.optim.Adam([\n",
        "    dict(params=model.parameters(), lr=0.00008),\n",
        "])\n",
        "\n",
        "# define learning rate scheduler (not used in this NB)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",
        ")\n",
        "\n",
        "# # load best saved model checkpoint from previous commit (if present)\n",
        "# if os.path.exists('../input/deepglobe-land-cover-classification-deeplabv3/best_model.pth'):\n",
        "#     model = torch.load('../input/deepglobe-land-cover-classification-deeplabv3/best_model.pth', map_location=DEVICE)\n",
        "#     print('Loaded pre-trained DeepLabV3+ model!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n90G1-alTp8z"
      },
      "outputs": [],
      "source": [
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfc_Pxf2TmwY"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwvavB1rTyjT"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# write the code for training and saving the best model using validation set\n",
        "if TRAINING:\n",
        "\n",
        "    best_iou_score = 0.0\n",
        "    train_logs_list, valid_logs_list = [], []\n",
        "\n",
        "    for i in range(0, EPOCHS):\n",
        "\n",
        "        # Perform training & validation\n",
        "        print('\\nEpoch: {}'.format(i))\n",
        "\n",
        "\n",
        "        # Save model if a better val IoU score is obtained\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbgH42dthmxA"
      },
      "outputs": [],
      "source": [
        "train_logs_df = pd.DataFrame(train_logs_list)\n",
        "valid_logs_df = pd.DataFrame(valid_logs_list)\n",
        "train_logs_df.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cAjmE-2UD8a"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "plt.plot(train_logs_df.index.tolist(), train_logs_df.iou_score.tolist(), lw=3, label = 'Train')\n",
        "plt.plot(valid_logs_df.index.tolist(), valid_logs_df.iou_score.tolist(), lw=3, label = 'Valid')\n",
        "plt.xlabel('Epochs', fontsize=20)\n",
        "plt.ylabel('IoU Score', fontsize=20)\n",
        "plt.title('IoU Score Plot', fontsize=20)\n",
        "plt.legend(loc='best', fontsize=16)\n",
        "plt.grid()\n",
        "plt.savefig('iou_score_plot.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lS9Z1IYNUHCm"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "plt.plot(train_logs_df.index.tolist(), train_logs_df.dice_loss.tolist(), lw=3, label = 'Train')\n",
        "plt.plot(valid_logs_df.index.tolist(), valid_logs_df.dice_loss.tolist(), lw=3, label = 'Valid')\n",
        "plt.xlabel('Epochs', fontsize=20)\n",
        "plt.ylabel('Dice Loss', fontsize=20)\n",
        "plt.title('Dice Loss Plot', fontsize=20)\n",
        "plt.legend(loc='best', fontsize=16)\n",
        "plt.grid()\n",
        "plt.savefig('dice_loss_plot.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhdoQ0MTWLcl"
      },
      "outputs": [],
      "source": [
        "sample_preds_folder = 'sample_predictions/'\n",
        "if not os.path.exists(sample_preds_folder):\n",
        "    os.makedirs(sample_preds_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cltD2klrdh8y"
      },
      "outputs": [],
      "source": [
        "if os.path.exists('./best_model_no_arg.pth'):\n",
        "    best_model = torch.load('./best_model_no_arg.pth', map_location=DEVICE)\n",
        "    print('Loaded Unet model from this run.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmqgP0z7phzZ"
      },
      "outputs": [],
      "source": [
        "# @title\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFe8ZdG6WL6b"
      },
      "source": [
        "Visualise the predictions output on some of the test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6UKYQm2WNSh"
      },
      "outputs": [],
      "source": [
        "for idx in range(7):\n",
        "\n",
        "    image, gt_mask = test_dataset[idx]\n",
        "    image_vis = test_dataset_vis[idx][0].astype('uint8')\n",
        "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
        "    # Predict test image\n",
        "    pred_mask = best_model(x_tensor)\n",
        "    pred_mask = pred_mask.detach().squeeze().cpu().numpy()\n",
        "    # Convert pred_mask from `CHW` format to `HWC` format\n",
        "    pred_mask = np.transpose(pred_mask,(1,2,0))\n",
        "    # Get prediction channel corresponding to foreground\n",
        "    pred_urban_land_heatmap = pred_mask[:,:,select_classes.index('urban_land')]\n",
        "    pred_mask = colour_code_segmentation(reverse_one_hot(pred_mask), select_class_rgb_values)\n",
        "    # Convert gt_mask from `CHW` format to `HWC` format\n",
        "    gt_mask = np.transpose(gt_mask,(1,2,0))\n",
        "    gt_mask = colour_code_segmentation(reverse_one_hot(gt_mask), select_class_rgb_values)\n",
        "    cv2.imwrite(os.path.join(sample_preds_folder, f\"sample_pred_{idx}.png\"), np.hstack([image_vis, gt_mask, pred_mask])[:,:,::-1])\n",
        "\n",
        "    visualize(\n",
        "        original_image = image_vis,\n",
        "        ground_truth_mask = gt_mask,\n",
        "        predicted_mask = pred_mask,\n",
        "        pred_urban_land_heatmap = pred_urban_land_heatmap\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd4Xa46wSkvG"
      },
      "source": [
        "# Task 3: Train the model with the data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxTWxR33qiZQ"
      },
      "outputs": [],
      "source": [
        "# Get train and val dataset instances with augmented data\n",
        "train_dataset = LandCoverDataset(\n",
        "    train_df,\n",
        "    augmentation=get_training_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "valid_dataset = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "test_dataset = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "\n",
        "# Get train and val data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
        "test_dataloader = DataLoader(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:17.806622Z",
          "iopub.status.busy": "2020-11-11T04:20:17.805771Z",
          "iopub.status.idle": "2020-11-11T04:20:21.985521Z",
          "shell.execute_reply": "2020-11-11T04:20:21.986028Z"
        },
        "id": "OnVwfVknQIt1",
        "papermill": {
          "duration": 4.6083,
          "end_time": "2020-11-11T04:20:21.986189",
          "exception": false,
          "start_time": "2020-11-11T04:20:17.377889",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Set flag to train the model or not. If set to 'False', only prediction is performed (using an older model checkpoint)\n",
        "TRAINING = True\n",
        "\n",
        "# Set num of epochs\n",
        "EPOCHS = 2\n",
        "\n",
        "# Set device: `cuda` or `cpu`\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# define loss function\n",
        "# loss = smp.utils.losses.DiceLoss()\n",
        "loss = DiceLoss()\n",
        "\n",
        "# loss = BCEDiceLoss()\n",
        "\n",
        "# define metrics\n",
        "metrics = [\n",
        "    smp.utils.metrics.IoU(threshold=0.5),\n",
        "]\n",
        "\n",
        "# define optimizer\n",
        "optimizer = torch.optim.Adam([\n",
        "    dict(params=model.parameters(), lr=0.00008),\n",
        "])\n",
        "\n",
        "# define learning rate scheduler (not used in this NB)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc64JsaLOhs-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:22.099274Z",
          "iopub.status.busy": "2020-11-11T04:20:22.098455Z",
          "iopub.status.idle": "2020-11-11T04:20:22.121316Z",
          "shell.execute_reply": "2020-11-11T04:20:22.120427Z"
        },
        "id": "uO7_OACaQIt1",
        "papermill": {
          "duration": 0.082187,
          "end_time": "2020-11-11T04:20:22.121494",
          "exception": false,
          "start_time": "2020-11-11T04:20:22.039307",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-u_RqwkdZrL"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T04:20:22.346852Z",
          "iopub.status.busy": "2020-11-11T04:20:22.345942Z",
          "iopub.status.idle": "2020-11-11T05:54:51.737107Z",
          "shell.execute_reply": "2020-11-11T05:54:51.736560Z"
        },
        "id": "IutdGndaQIt2",
        "papermill": {
          "duration": 5669.449912,
          "end_time": "2020-11-11T05:54:51.737233",
          "exception": false,
          "start_time": "2020-11-11T04:20:22.287321",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "if TRAINING:\n",
        "\n",
        "    best_iou_score = 0.0\n",
        "    train_logs_list, valid_logs_list = [], []\n",
        "\n",
        "    for i in range(0, EPOCHS):\n",
        "\n",
        "        # Perform training & validation\n",
        "\n",
        "\n",
        "        # Save model if a better val IoU score is obtained\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T05:54:55.915262Z",
          "iopub.status.busy": "2020-11-11T05:54:55.914377Z",
          "iopub.status.idle": "2020-11-11T05:54:56.035770Z",
          "shell.execute_reply": "2020-11-11T05:54:56.036521Z"
        },
        "id": "acA_0-BwQIt2",
        "papermill": {
          "duration": 1.141206,
          "end_time": "2020-11-11T05:54:56.036700",
          "exception": false,
          "start_time": "2020-11-11T05:54:54.895494",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# load best saved model checkpoint from the current run\n",
        "if os.path.exists('./best_model.pth'):\n",
        "    best_model = torch.load('./best_model.pth', map_location=DEVICE)\n",
        "    print('Loaded Unet model from this run.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir2XvVrd_aRE"
      },
      "source": [
        "Visualise the predictions output on some of the test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T06:02:47.295808Z",
          "iopub.status.busy": "2020-11-11T06:02:47.294829Z",
          "iopub.status.idle": "2020-11-11T06:02:47.304972Z",
          "shell.execute_reply": "2020-11-11T06:02:47.305607Z"
        },
        "id": "Qd0VXZUbQIt6",
        "papermill": {
          "duration": 1.572864,
          "end_time": "2020-11-11T06:02:47.305773",
          "exception": false,
          "start_time": "2020-11-11T06:02:45.732909",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_logs_df = pd.DataFrame(train_logs_list)\n",
        "valid_logs_df = pd.DataFrame(valid_logs_list)\n",
        "train_logs_df.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T06:02:50.363061Z",
          "iopub.status.busy": "2020-11-11T06:02:50.356228Z",
          "iopub.status.idle": "2020-11-11T06:02:50.731842Z",
          "shell.execute_reply": "2020-11-11T06:02:50.732339Z"
        },
        "id": "w2r8oaSJQIt6",
        "papermill": {
          "duration": 1.92074,
          "end_time": "2020-11-11T06:02:50.732517",
          "exception": false,
          "start_time": "2020-11-11T06:02:48.811777",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "plt.plot(train_logs_df.index.tolist(), train_logs_df.iou_score.tolist(), lw=3, label = 'Train')\n",
        "plt.plot(valid_logs_df.index.tolist(), valid_logs_df.iou_score.tolist(), lw=3, label = 'Valid')\n",
        "plt.xlabel('Epochs', fontsize=20)\n",
        "plt.ylabel('IoU Score', fontsize=20)\n",
        "plt.title('IoU Score Plot', fontsize=20)\n",
        "plt.legend(loc='best', fontsize=16)\n",
        "plt.grid()\n",
        "plt.savefig('iou_score_plot.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-11-11T06:02:54.381389Z",
          "iopub.status.busy": "2020-11-11T06:02:54.374637Z",
          "iopub.status.idle": "2020-11-11T06:02:54.740895Z",
          "shell.execute_reply": "2020-11-11T06:02:54.741457Z"
        },
        "id": "6bBh6uAsQIt6",
        "papermill": {
          "duration": 1.939009,
          "end_time": "2020-11-11T06:02:54.741622",
          "exception": false,
          "start_time": "2020-11-11T06:02:52.802613",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "plt.plot(train_logs_df.index.tolist(), train_logs_df.dice_loss.tolist(), lw=3, label = 'Train')\n",
        "plt.plot(valid_logs_df.index.tolist(), valid_logs_df.dice_loss.tolist(), lw=3, label = 'Valid')\n",
        "plt.xlabel('Epochs', fontsize=20)\n",
        "plt.ylabel('Dice Loss', fontsize=20)\n",
        "plt.title('Dice Loss Plot', fontsize=20)\n",
        "plt.legend(loc='best', fontsize=16)\n",
        "plt.grid()\n",
        "plt.savefig('dice_loss_plot.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZDOec7ZOxGX"
      },
      "source": [
        "# Task 4: BCEDiceloss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyOzaq-6tnyB"
      },
      "source": [
        "### Now, we let's try with different loss function: BCEDiceloss. We will define our own BCEDiceloss with pytorch.\n",
        "\n",
        "You can try implementing or importing different loss functions from pytorch library.  \n",
        "Also, here's a survey for loss functions used for image segmentation: https://arxiv.org/pdf/2006.14822.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCr0JaY5r8Kn"
      },
      "outputs": [],
      "source": [
        "#code for BCEDICEloss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umoWmCNIj9r-"
      },
      "outputs": [],
      "source": [
        "# Get train and val dataset instances with augmented data\n",
        "train_dataset = LandCoverDataset(\n",
        "    train_df,\n",
        "    augmentation=get_training_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "valid_dataset = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "test_dataset = LandCoverDataset(\n",
        "    valid_df,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "\n",
        "# Get train and val data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
        "test_dataloader = DataLoader(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HiKxTtMOze-"
      },
      "outputs": [],
      "source": [
        "# Set flag to train the model or not. If set to 'False', only prediction is performed (using an older model checkpoint)\n",
        "TRAINING = True\n",
        "\n",
        "# Set num of epochs\n",
        "EPOCHS = 2\n",
        "\n",
        "# Set device: `cuda` or `cpu`\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# define loss function\n",
        "# loss = BCEDiceLoss()\n",
        "\n",
        "# define metrics\n",
        "metrics = [\n",
        "    smp.utils.metrics.IoU(threshold=0.5),\n",
        "]\n",
        "\n",
        "# define optimizer\n",
        "optimizer = torch.optim.Adam([\n",
        "    dict(params=model.parameters(), lr=0.00008),\n",
        "])\n",
        "\n",
        "# define learning rate scheduler (not used in this NB)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",
        ")\n",
        "\n",
        "# load best saved model checkpoint from previous commit (if present)\n",
        "# if os.path.exists('../input/deepglobe-land-cover-classification-deeplabv3/best_model.pth'):\n",
        "#     model = torch.load('../input/deepglobe-land-cover-classification-deeplabv3/best_model.pth', map_location=DEVICE)\n",
        "#     print('Loaded pre-trained DeepLabV3+ model!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MBHg_qIO9b5"
      },
      "outputs": [],
      "source": [
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0UrZHjiPBON"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G75L-7HqPFDG"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "if TRAINING:\n",
        "\n",
        "    best_iou_score = 0.0\n",
        "    train_logs_list, valid_logs_list = [], []\n",
        "\n",
        "    for i in range(0, EPOCHS):\n",
        "\n",
        "        # Perform training & validation\n",
        "\n",
        "        # Save model if a better val IoU score is obtained\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygF3WtW5YNZo"
      },
      "outputs": [],
      "source": [
        "train_logs_df = pd.DataFrame(train_logs_list)\n",
        "valid_logs_df = pd.DataFrame(valid_logs_list)\n",
        "train_logs_df.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHeEL84mQMmE"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "plt.plot(train_logs_df.index.tolist(), train_logs_df.iou_score.tolist(), lw=3, label = 'Train')\n",
        "plt.plot(valid_logs_df.index.tolist(), valid_logs_df.iou_score.tolist(), lw=3, label = 'Valid')\n",
        "plt.xlabel('Epochs', fontsize=20)\n",
        "plt.ylabel('IoU Score', fontsize=20)\n",
        "plt.title('IoU Score Plot', fontsize=20)\n",
        "plt.legend(loc='best', fontsize=16)\n",
        "plt.grid()\n",
        "plt.savefig('iou_score_plot.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qch1Sw2QO_O"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "plt.plot(train_logs_df.index.tolist(), train_logs_df.bce_dice_loss.tolist(), lw=3, label = 'Train')\n",
        "plt.plot(valid_logs_df.index.tolist(), valid_logs_df.bce_dice_loss.tolist(), lw=3, label = 'Valid')\n",
        "plt.xlabel('Epochs', fontsize=20)\n",
        "plt.ylabel('BCEDice Loss', fontsize=20)\n",
        "plt.title('BCEDice Loss Plot', fontsize=20)\n",
        "plt.legend(loc='best', fontsize=16)\n",
        "plt.grid()\n",
        "plt.savefig('dice_loss_plot.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEuQ7TPBTE0u"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T62UgBVoulNM"
      },
      "source": [
        "**Discussion**  \n",
        "We have trained the same model with two different losses: Diceloss and BCEDiceloss.\n",
        "\n",
        "What difference do you see from the IOU score?   \n",
        "Try more epochs for more detailed comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhN3q43WvLLr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BgJJvPfvLtw"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I216sWjnh0Mo"
      },
      "source": [
        "# Task 5: compute the 1) area of let's say water (or any other class) on the test set ground truth, 2) area of water on the predicted masks on the same test set and compute the difference between\n",
        "**what is the error of your predictions in terms of water area/surface?**\n",
        "\n",
        "Hint: calculate the area of mask in the result image in pixel.\n",
        "https://stackoverflow.com/questions/58068315/calculate-the-area-of-the-masks-in-pixels-in-grey-scale-images-with-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CICJ73mfl6p3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "TfbTqV1tQIto",
        "1JuDPChTQItq",
        "cdGCpfjsQItt",
        "714IWFiotSka",
        "EEU8DKdFQIty"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "comp0189",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "papermill": {
      "duration": 6201.325856,
      "end_time": "2020-11-11T06:02:57.609445",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-11-11T04:19:36.283589",
      "version": "2.1.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "eafeb9b2355845a5f1288e84c0298a3c02747aa0b0fc391e5775e47e4b2d1c65"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
